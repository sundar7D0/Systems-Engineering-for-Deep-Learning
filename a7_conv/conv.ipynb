{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"conv.ipynb","private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"ty8yCO7usQo0"},"source":["#imports\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","torch.__version__\n","import math\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X-137nLHzSqj"},"source":["#global_variables\n","N,H,W,M,C,R,S,Sx,Sy=2,5,5,2,2,2,2,1,1\n","E,F=math.ceil((H-R)/Sx)+1,math.ceil((W-S)/Sy)+1\n","inp=torch.rand(N,2*C,H,W)\n","out=torch.zeros(N,M,E,F)\n","#wgt=torch.rand(M,C,R,S)\n","#bias=torch.zeros(N,M,E,F)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KFNFkkZ-x5OO"},"source":["index='6'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YzC9TFjGt04Y"},"source":["#[N,H,W,C,R,S,C,M,Sx,Sy,g]\n","config={'0':[8,4,4,3,3,4,3,2,2,2,1],#small h,w,r,s,m, unequal strides, unequal r, s\n","        '1':[8,20,20,3,3,4,3,2,2,2,1],#big h,w;small r,s,m, unequal r, s, unequal strides\n","        '2':[8,20,20,3,10,10,3,2,2,2,1],#big h,w,r,s, equal, non-unity strides\n","        '3':[8,20,20,3,3,10,3,2,2,3,1],#big h,w;unequal r,s, unequal strides\n","        '4':[8,4,20,3,3,3,3,2,2,3,1],#unequal h,w;small r,s,m, unequal strides\n","        '5':[8,10,10,3,3,3,3,2,8,8,1],#equal non-unity wide strides \n","        '6':[8,10,10,3,3,3,3,2,5,2,1],#unequal non-unity strides\n","        '7':[8,20,20,10,3,3,10,10,2,3,1],#big h,w,c, m;small r,s,m;unequal strides\n","        '8':[8,4,4,20,3,3,20,10,2,3,2],  #big c, m;small r,s,h,w unequal strides\n","        '9':[8,10,10,10,3,3,10,10,2,2,1],  #big h,w,m,c,non-unity strides\n","        }\n","N=config[index][0]\n","H=config[index][1]\n","W=config[index][2]\n","C=config[index][3]\n","R=config[index][4]\n","S=config[index][5]\n","C=config[index][6]\n","M=config[index][7]\n","Sx=config[index][8]\n","Sy=config[index][9]\n","g=config[index][10]\n","E,F=math.floor((H-R)/Sx)+1,math.floor((W-S)/Sy)+1\n","inp=torch.rand(N,C,H,W)\n","out=torch.zeros(N,M,E,F)\n","print('N:%d,H:%d,W:%d,C:%d;R:%d,S:%d,C:%d,M:%d;Sx:%d,Sy:%d,g:%d'%(N,H,W,C,R,S,C,M,Sx,Sy,g))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JNrgJSN0wDlr"},"source":["#0.nn.conv2d\n","i_max=100\n","avg_time=0\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","conv0=nn.Conv2d(C,M,kernel_size=(R,S),stride=(Sx,Sy),groups=g).to(device)\n","inp=inp.to(device)\n","for i in range(i_max):\n","    start_time=time.time()\n","    out0=conv0(inp)\n","    end_time=time.time()\n","    avg_time+=end_time-start_time\n","print('Total_time-1:',avg_time/i_max)\n","wgt0=conv0.weight\n","bias0=conv0.bias"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bod3l8xzbn47"},"source":["conv1=nn.Conv2d(2*C,12,kernel_size=(R,S),stride=(Sx,Sy),groups=2*C,bias=None)\n","out_=conv1(inp)\n","print(out_.shape)\n","print(inp.shape)\n","print(conv1.weight.shape)\n","#print(conv1.bias.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oUqQJWnxdjxW"},"source":["wit=conv1.weight\n","outo=torch.Tensor([])\n","for g in range(3):\n","    wit_=wit[g*4:g*4+4,:,:,:]#.reshape(1,-1,2,2)\n","    outo=torch.cat((outo,F.conv2d(inp,wit_,None,groups=4)),axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bc68uf3BhpyG"},"source":["print(outo,out_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nhXXj00bguEq"},"source":["outi=F.conv2d(inp,wit,bias=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jLsrOEbSiKTi"},"source":["print(outi.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MnqsXJq7hKAD"},"source":["print('Equal1: ',torch.all(torch.abs(out_-outo)<9.6e-1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tB1likW2hTKy"},"source":["print(out_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pp5M5nTlhiOF"},"source":["print(outi)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"afbyQkMmUSVq"},"source":["print(out0.shape,wgt0.shape,bias0.shape,inp.shape)\n","print(out0.dtype,out.dtype,bias0.dtype,wgt0.dtype,inp.dtype)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xo43d4chvWtB"},"source":["#1.direct_convolution\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","avg_time=0\n","i_max=1\n","inp1=inp.clone().to(device)\n","wgt1=wgt0.clone().to(device)\n","bias1=bias0.clone().to(device)\n","avg_time=0\n","for i in range(i_max):\n","    out1=out.clone().to(device)\n","    start_time=time.time()\n","    for n in range(N):\n","        for e in range(E):\n","            for f in range(F):\n","                for m in range(M):\n","                    if e*Sx+R<H and f*Sy+S<W:\n","                        o=out1[n][m][e][f]\n","                        for c in range(C):\n","                            for r in range(R):\n","                                for s in range(S):\n","                                    o+=inp1[n][c][Sx*e+r][Sy*f+s]*wgt1[m][c][r][s]\n","                        out1[n][m][e][f]=o+bias1[m]\n","    end_time=time.time()\n","    avg_time+=end_time-start_time\n","print('Total_time0:',(avg_time)/i_max)\n","print('Equal0: ',torch.all(torch.eq(out0, out1)))\n","print('Equal1: ',torch.all(torch.abs(out0-out1)<2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lX9NkoGomUJ2"},"source":["print(out1.shape,out0.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VzC-51avy2xU"},"source":["#2.im2col_convolution\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","avg_time=0\n","i_max=2\n","inp2=inp.clone().to(device)\n","wgt2=wgt0.clone().to(device)\n","bias2=bias0.clone().to(device)\n","for i in range(i_max):\n","    r_inp=torch.Tensor([]).to(device)\n","    out2=torch.Tensor([]).to(device)\n","    start_time=time.time()\n","    r_wgt=wgt2.view(M,-1)\n","    for e in range(E):\n","        for f in range(F):\n","            r_inp=torch.cat((r_inp,inp2[:,:,Sx*e:Sx*e+R,Sy*f:Sy*f+S].reshape(N,-1).T),axis=-1)\n","    r_out=torch.matmul(r_wgt,r_inp)+torch.unsqueeze(bias0,axis=-1)  \n","    for n in range(N):\n","        out2=torch.cat((out2,r_out[:,n::N].reshape(1,-1,E,F)))\n","    end_time=time.time()\n","    avg_time+=end_time-start_time\n","print('Equal2: ',torch.all(torch.abs(out0-out2)<1e-5))\n","print('Total_time2:',avg_time/i_max)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_dzYje9qcQtT"},"source":["#winograd_conv\n","import sys\n","from torch import tensor\n","\n","\"\"\"\n","author: Adam Dziedzic ady@uchicago.edu\n","Based on the paper: https://arxiv.org/abs/1509.09308\n","\"\"\"\n","\n","\n","class Winograd(object):\n","    B = tensor(\n","        [[1.0, 0.0, 0.0, 0.0],\n","         [0.0, 1.0, -1.0, 1.0],\n","         [-1.0, 1.0, 1.0, 0.0],\n","         [0.0, 0.0, 0.0, -1.0]]).to(device)\n","    B_T = B.transpose(1, 0)\n","    G = tensor(\n","        [[1.0, 0.0, 0.0],\n","         [0.5, 0.5, 0.5],\n","         [0.5, -0.5, 0.5],\n","         [0.0, 0.0, 1.0]]).to(device)\n","    G_T = G.transpose(1, 0)\n","    A = tensor([[1.0, 0.0],\n","                [1.0, 1.0],\n","                [1.0, -1.0],\n","                [0.0, -1.0]]).to(device)\n","    A_T = A.transpose(1, 0)\n","\n","    def __init__(self, filter_value=None):\n","        super(Winograd, self).__init__()\n","\n","        if filter_value is not None:\n","            self.filter = filter_value\n","\n","    @staticmethod\n","    def forward(input, filter):\n","        \"\"\"\n","        Compute Winograd convolution.\n","        :param input:\n","        :param filter:\n","        :return: output\n","        \"\"\"\n","        N, C, H, W = input.size()\n","        K, Cprime, r, rprime = filter.size()\n","        assert H == W\n","        assert r == rprime\n","        assert C == Cprime\n","        m = 2\n","        a = m + r - 1\n","        # TODO pad with zeros the input for perfect tiling and slice the output.\n","        overlap = r - 1\n","        if (H >= 4 and H % 2 == 0) is False:\n","            raise Exception(\"Only input for perfect tiling is supported.\")\n","        input = torch.transpose(input, 0, 1)\n","        assert input.size() == (C, N, H, W)\n","        # ntile = int(math.ceil(H//a))\n","        # P = N * ntile * ntile\n","        T = (W - a) // overlap + 1  # tiles_per_channel\n","        P = N * T * T\n","        U = torch.zeros(K, C, a, a).to(device)\n","        V = torch.zeros(C, P, a, a).to(device)\n","        for k in range(K):\n","            for c in range(C):\n","                U[k, c] = torch.matmul(Winograd.G,\n","                                       torch.matmul(filter[k, c], Winograd.G_T))\n","        for n in range(N):\n","            for tH in range(T):\n","                for tW in range(T):\n","                    for c in range(C):\n","                        b = n * (T * T) + tH * T + tW\n","                        vH = tH * (r - 1)\n","                        vW = tW * (r - 1)\n","                        V[c, b] = torch.matmul(Winograd.B_T, torch.matmul(\n","                            input[c, n, vH:vH + a, vW:vW + a], Winograd.B))\n","        M = torch.zeros(K, P, a, a).to(device)\n","        for k in range(K):\n","            for b in range(P):\n","                for c in range(C):\n","                    M[k, b] += U[k, c] * V[c, b]\n","        # M = torch.matmul(U, V)\n","        out_size = H - r + 1\n","        Y = torch.zeros(K, N, out_size, out_size).to(device)\n","        for k in range(K):\n","            for n in range(N):\n","                for tH in range(T):\n","                    for tW in range(T):\n","                        b = n * (T * T) + tH * T + tW\n","                        oH = tH * m\n","                        oW = tW * m\n","                        Y[k, n, oH:oH + m, oW:oW + m] = torch.matmul(\n","                            Winograd.A_T, torch.matmul(M[k, b], Winograd.A))\n","\n","        Y = torch.transpose(Y, 0, 1)\n","        return Y\n","\n","    @staticmethod\n","    def winograd_F_2_3(input, filter):\n","        \"\"\"\n","        Compute winograd convolution with output of size 2x2 and filter of size\n","        3x3.\n","        :param input: 4x4\n","        :param filter: 3x3\n","        :return: 2x2\n","        \"\"\"\n","        U = torch.matmul(Winograd.G, torch.matmul(filter, Winograd.G_T))\n","        V = torch.matmul(Winograd.B_T, torch.matmul(input, Winograd.B))\n","        return torch.matmul(Winograd.A_T, torch.matmul(U * V, Winograd.A))\n","\n","    @staticmethod\n","    def winograd_F_1_3(input, filter):\n","        \"\"\"\n","        Compute winograd convolution with output of size 1x1 and filter of size\n","        3x3. Input size is 3x3.\n","        :param input: 3x3\n","        :param filter: 3x3\n","        :return: 2x2\n","        \"\"\"\n","        return input * filter\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLdw-nKHy8V3"},"source":["#3.winograd_convolution\n","#Winograd.winograd_F_2_3(x, y)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","avg_time=0\n","i_max=2\n","inp3=inp.clone().to(device)\n","wgt3=wgt0.clone().to(device)\n","bias3=bias0.clone().to(device)\n","for i in range(i_max):\n","    start_time=time.time()\n","    out3=Winograd.forward(inp3,wgt3)#+bias3\n","    end_time=time.time()\n","    avg_time+=(end_time-start_time)\n","print('Total_time3:',avg_time/i_max)\n","print('Equal2: ',torch.all(torch.abs(out0-out3)<1))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ExNVRzfhxQG"},"source":["#winograd_conv2\n","from __future__ import print_function\n","from sympy import symbols, Matrix, Poly, zeros, eye, Indexed, simplify, IndexedBase, init_printing, pprint\n","from operator import mul\n","from functools import reduce\n","\n","def At(a,m,n):\n","    return Matrix(m, n, lambda i,j: a[i]**j)\n","\n","def A(a,m,n):\n","    return At(a, m-1, n).row_insert(m-1, Matrix(1, n, lambda i,j: 1 if j==n-1 else 0))\n","\n","def T(a,n):\n","    return Matrix(Matrix.eye(n).col_insert(n, Matrix(n, 1, lambda i,j: -a[i]**n)))\n","\n","def Lx(a,n):\n","    x=symbols('x')\n","    return Matrix(n, 1, lambda i,j: Poly((reduce(mul, ((x-a[k] if k!=i else 1) for k in range(0,n)), 1)).expand(basic=True), x))\n","\n","def F(a,n):\n","    return Matrix(n, 1, lambda i,j: reduce(mul, ((a[i]-a[k] if k!=i else 1) for k in range(0,n)), 1))\n","\n","def Fdiag(a,n):\n","    f=F(a,n)\n","    return Matrix(n, n, lambda i,j: (f[i,0] if i==j else 0))\n","\n","def FdiagPlus1(a,n):\n","    f = Fdiag(a,n-1)\n","    f = f.col_insert(n-1, zeros(n-1,1))\n","    f = f.row_insert(n-1, Matrix(1,n, lambda i,j: (1 if j==n-1 else 0)))\n","    return f\n","\n","def L(a,n):\n","    lx = Lx(a,n)\n","    f = F(a, n)\n","    return Matrix(n, n, lambda i,j: lx[i, 0].nth(j)/f[i]).T\n","\n","def Bt(a,n):\n","    return L(a,n)*T(a,n)\n","\n","def B(a,n):\n","    return Bt(a,n-1).row_insert(n-1, Matrix(1, n, lambda i,j: 1 if j==n-1 else 0))\n","\n","FractionsInG=0\n","FractionsInA=1\n","FractionsInB=2\n","FractionsInF=3\n","\n","def cookToomFilter(a,n,r,fractionsIn=FractionsInG):\n","    alpha = n+r-1\n","    f = FdiagPlus1(a,alpha)\n","    if f[0,0] < 0:\n","        f[0,:] *= -1\n","    if fractionsIn == FractionsInG:\n","        AT = A(a,alpha,n).T\n","        G = (A(a,alpha,r).T*f**(-1)).T\n","        BT = f * B(a,alpha).T\n","    elif fractionsIn == FractionsInA:\n","        BT = f * B(a,alpha).T\n","        G = A(a,alpha,r)\n","        AT = (A(a,alpha,n)).T*f**(-1)\n","    elif fractionsIn == FractionsInB:\n","        AT = A(a,alpha,n).T\n","        G = A(a,alpha,r)\n","        BT = B(a,alpha).T\n","    else:\n","        AT = A(a,alpha,n).T\n","        G = A(a,alpha,r)\n","        BT = f * B(a,alpha).T\n","    return (AT,G,BT,f)\n","\n","\n","def filterVerify(n, r, AT, G, BT):\n","\n","    alpha = n+r-1\n","\n","    di = IndexedBase('d')\n","    gi = IndexedBase('g')\n","    d = Matrix(alpha, 1, lambda i,j: di[i])\n","    g = Matrix(r, 1, lambda i,j: gi[i])\n","\n","    V = BT*d\n","    U = G*g\n","    M = U.multiply_elementwise(V)\n","    Y = simplify(AT*M)\n","\n","    return Y\n","\n","def convolutionVerify(n, r, B, G, A):\n","\n","    di = IndexedBase('d')\n","    gi = IndexedBase('g')\n","\n","    d = Matrix(n, 1, lambda i,j: di[i])\n","    g = Matrix(r, 1, lambda i,j: gi[i])\n","\n","    V = A*d\n","    U = G*g\n","    M = U.multiply_elementwise(V)\n","    Y = simplify(B*M)\n","\n","    return Y\n","\n","def showCookToomFilter(a,n,r,fractionsIn=FractionsInG):\n","\n","    AT,G,BT,f = cookToomFilter(a,n,r,fractionsIn)\n","\n","    print (\"AT = \")\n","    pprint(AT)\n","    print (\"\")\n","\n","    print (\"G = \")\n","    pprint(G)\n","    print (\"\")\n","\n","    print (\"BT = \")\n","    pprint(BT)\n","    print (\"\")\n","\n","    if fractionsIn != FractionsInF:\n","        print (\"FIR filter: AT*((G*g)(BT*d)) =\")\n","        pprint(filterVerify(n,r,AT,G,BT))\n","        print (\"\")\n","\n","    if fractionsIn == FractionsInF:\n","        print (\"fractions = \")\n","        pprint(f)\n","        print (\"\")\n","\n","def showCookToomConvolution(a,n,r,fractionsIn=FractionsInG):\n","\n","    AT,G,BT,f = cookToomFilter(a,n,r,fractionsIn)\n","\n","    B = BT.transpose()\n","    A = AT.transpose()\n","\n","    print (\"A = \")\n","    pprint(A)\n","    print (\"\")\n","\n","    print (\"G = \")\n","    pprint(G)\n","    print (\"\")\n","\n","    print (\"B = \")\n","    pprint(B)\n","    print (\"\")\n","\n","    if fractionsIn != FractionsInF:\n","        print (\"Linear Convolution: B*((G*g)(A*d)) =\")\n","        pprint(convolutionVerify(n,r,B,G,A))\n","        print (\"\")\n","\n","    if fractionsIn == FractionsInF:\n","        print (\"fractions = \")\n","        pprint(f)\n","        print (\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lkGmb7Dn3BES"},"source":["inp3=torch.randn(8,3,6,6)\n","wgt3=torch.randn(8,3,2,2)\n","conv3=nn.Conv2d(3,8,kernel_size=(2,2))\n","wgt3=conv3.weight\n","bias3=conv3.bias\n","out3=conv3(inp3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"llsr9_He5hZ6"},"source":["wgt3.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w-RUzRUFzEF2"},"source":["gg=[[1/4,0],[-1/6,-1/6],[-1/6,1/6],[1/24,1/12],[1/24,-1/12],[0,1]]\n","gg=torch.Tensor(gg)\n","bb=[[4,0,0,0,0,0],[0,-4,4,-2,2,4],[-5,-4,-4,-1,-1,0],[0,1,-1,2,-2,-5],[1,1,1,1,1,0],[0,0,0,0,0,1]]\n","bb=torch.Tensor(bb)\n","#print(gg.shape,wgt3.shape,torch.matmul(gg,wgt3).shape)\n","U=torch.matmul(torch.matmul(gg,wgt3),gg.T)\n","V=torch.matmul(torch.matmul(bb.T,inp3),bb)\n","aa=[[1,0,0,0,0],[1,1,1,1,1],[1,-1,1,-1,1],[1,2,4,8,16],[1,-2,4,-8,16],[0,0,0,0,1]]\n","aa=torch.Tensor(aa)\n","out_=torch.matmul(torch.matmul(aa.T,U.mul(V)),aa)+bias3.reshape(8,1,1,1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ILn1cxC64Di7"},"source":["out_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hAdrC_Kq6Vd-"},"source":["out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6wvNa-AjhzEL"},"source":["showCookToomConvolution((0,1,-1,2,-2),5,2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bqIMrRPjapmk"},"source":["#fft_conv\n","from functools import partial\n","from typing import Tuple, Union, Iterable\n","\n","import torch\n","from torch import nn, Tensor\n","from torch.fft import rfftn, irfftn\n","import torch.nn.functional as f\n","\n","\n","def complex_matmul(a: Tensor, b: Tensor, groups: int = 1) -> Tensor:\n","    \"\"\"Multiplies two complex-valued tensors.\"\"\"\n","    # Scalar matrix multiplication of two tensors, over only the first channel\n","    # dimensions. Dimensions 3 and higher will have the same shape after multiplication.\n","    # We also allow for \"grouped\" multiplications, where multiple sections of channels\n","    # are multiplied independently of one another (required for group convolutions).\n","    scalar_matmul = partial(torch.einsum, \"agc..., gbc... -> agb...\")\n","    a = a.view(a.size(0), groups, -1, *a.shape[2:])\n","    b = b.view(groups, -1, *b.shape[1:])\n","\n","    # Compute the real and imaginary parts independently, then manually insert them\n","    # into the output Tensor.  This is fairly hacky but necessary for PyTorch 1.7.0,\n","    # because Autograd is not enabled for complex matrix operations yet.  Not exactly\n","    # idiomatic PyTorch code, but it should work for all future versions (>= 1.7.0).\n","    real = scalar_matmul(a.real, b.real) - scalar_matmul(a.imag, b.imag)\n","    imag = scalar_matmul(a.imag, b.real) + scalar_matmul(a.real, b.imag)\n","    c = torch.zeros(real.shape, dtype=torch.complex64, device=a.device)\n","    c.real, c.imag = real, imag\n","\n","    return c.view(c.size(0), -1, *c.shape[3:])\n","\n","\n","def to_ntuple(val: Union[int, Iterable[int]], n: int) -> Tuple[int, ...]:\n","    \"\"\"Casts to a tuple with length 'n'.  Useful for automatically computing the\n","    padding and stride for convolutions, where users may only provide an integer.\n","    Args:\n","        val: (Union[int, Iterable[int]]) Value to cast into a tuple.\n","        n: (int) Desired length of the tuple\n","    Returns:\n","        (Tuple[int, ...]) Tuple of length 'n'\n","    \"\"\"\n","    if isinstance(val, Iterable):\n","        out = tuple(val)\n","        if len(out) == n:\n","            return out\n","        else:\n","            raise ValueError(f\"Cannot cast tuple of length {len(out)} to length {n}.\")\n","    else:\n","        return n * (val,)\n","\n","\n","def fft_conv(\n","    signal: Tensor,\n","    kernel: Tensor,\n","    bias: Tensor = None,\n","    padding: Union[int, Iterable[int]] = 0,\n","    stride: Union[int, Iterable[int]] = 1,\n","    groups: int = 1,\n",") -> Tensor:\n","    \"\"\"Performs N-d convolution of Tensors using a fast fourier transform, which\n","    is very fast for large kernel sizes. Also, optionally adds a bias Tensor after\n","    the convolution (in order ot mimic the PyTorch direct convolution).\n","    Args:\n","        signal: (Tensor) Input tensor to be convolved with the kernel.\n","        kernel: (Tensor) Convolution kernel.\n","        bias: (Tensor) Bias tensor to add to the output.\n","        padding: (Union[int, Iterable[int]) Number of zero samples to pad the\n","            input on the last dimension.\n","        stride: (Union[int, Iterable[int]) Stride size for computing output values.\n","    Returns:\n","        (Tensor) Convolved tensor\n","    \"\"\"\n","    # Cast padding & stride to tuples.\n","    padding_ = to_ntuple(padding, n=signal.ndim - 2)\n","    stride_ = to_ntuple(stride, n=signal.ndim - 2)\n","\n","    # Pad the input signal & kernel tensors\n","    signal_padding = [p for p in padding_[::-1] for _ in range(2)]\n","    signal = f.pad(signal, signal_padding)\n","\n","    # Because PyTorch computes a *one-sided* FFT, we need the final dimension to\n","    # have *even* length.  Just pad with one more zero if the final dimension is odd.\n","    if signal.size(-1) % 2 != 0:\n","        signal_ = f.pad(signal, [0, 1])\n","    else:\n","        signal_ = signal\n","\n","    kernel_padding = [\n","        pad\n","        for i in reversed(range(2, signal_.ndim))\n","        for pad in [0, signal_.size(i) - kernel.size(i)]\n","    ]\n","    padded_kernel = f.pad(kernel, kernel_padding)\n","\n","    # Perform fourier convolution -- FFT, matrix multiply, then IFFT\n","    # signal_ = signal_.reshape(signal_.size(0), groups, -1, *signal_.shape[2:])\n","    signal_fr = rfftn(signal_, dim=tuple(range(2, signal.ndim)))\n","    kernel_fr = rfftn(padded_kernel, dim=tuple(range(2, signal.ndim)))\n","\n","    kernel_fr.imag *= -1\n","    output_fr = complex_matmul(signal_fr, kernel_fr, groups=groups)\n","    output = irfftn(output_fr, dim=tuple(range(2, signal.ndim)))\n","\n","    # Remove extra padded values\n","    crop_slices = [slice(0, output.size(0)), slice(0, output.size(1))] + [\n","        slice(0, (signal.size(i) - kernel.size(i) + 1), stride_[i - 2])\n","        for i in range(2, signal.ndim)\n","    ]\n","    output = output[crop_slices].contiguous()\n","\n","    # Optionally, add a bias term before returning.\n","    if bias is not None:\n","        bias_shape = tuple([1, -1] + (signal.ndim - 2) * [1])\n","        output += bias.view(bias_shape)\n","\n","    return output\n","\n","\n","class _FFTConv(nn.Module):\n","    \"\"\"Base class for PyTorch FFT convolution layers.\"\"\"\n","\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        kernel_size: Union[int, Iterable[int]],\n","        padding: Union[int, Iterable[int]] = 0,\n","        stride: Union[int, Iterable[int]] = 1,\n","        groups: int = 1,\n","        bias: bool = True,\n","        ndim: int = 1,\n","    ):\n","        \"\"\"\n","        Args:\n","            in_channels: (int) Number of channels in input tensors\n","            out_channels: (int) Number of channels in output tensors\n","            kernel_size: (Union[int, Iterable[int]) Square radius of the kernel\n","            padding: (Union[int, Iterable[int]) Number of zero samples to pad the\n","                input on the last dimension.\n","            stride: (Union[int, Iterable[int]) Stride size for computing output values.\n","            bias: (bool) If True, includes bias, which is added after convolution\n","        \"\"\"\n","        super().__init__()\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.kernel_size = kernel_size\n","        self.padding = padding\n","        self.stride = stride\n","        self.groups = groups\n","        self.use_bias = bias\n","\n","        if in_channels % 2 != 0:\n","            raise ValueError(\n","                \"'in_channels' must be divisible by 'groups'.\"\n","                f\"Found: in_channels={in_channels}, groups={groups}.\"\n","            )\n","        if out_channels % 2 != 0:\n","            raise ValueError(\n","                \"'out_channels' must be divisible by 'groups'.\"\n","                f\"Found: out_channels={out_channels}, groups={groups}.\"\n","            )\n","\n","        kernel_size = to_ntuple(kernel_size, ndim)\n","        self.weight = nn.Parameter(\n","            torch.randn(out_channels, in_channels // groups, *kernel_size)\n","        )\n","        self.bias = nn.Parameter(torch.randn(out_channels,)) if bias else None\n","\n","    def forward(self, signal):\n","        return fft_conv(\n","            signal,\n","            self.weight,\n","            bias=self.bias,\n","            padding=self.padding,\n","            stride=self.stride,\n","            groups=self.groups,\n","        )\n","\n","\n","FFTConv1d = partial(_FFTConv, ndim=1)\n","FFTConv2d = partial(_FFTConv, ndim=2)\n","FFTConv3d = partial(_FFTConv, ndim=3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4dfNtFfIy-Xm"},"source":["#4.fft_convolution\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","avg_time=0\n","i_max=5\n","inp4=inp.clone().to(device)\n","wgt4=wgt0.clone().to(device)\n","bias4=bias0.clone().to(device)\n","for i in range(i_max):\n","    start_time=time.time()\n","    out4 = fft_conv(inp4, wgt4, bias=bias4,stride=(Sx,Sy),groups=g)\n","    end_time=time.time()\n","    avg_time+=end_time-start_time\n","print('Total_time4:',avg_time/i_max)\n","print('Equal4: ',torch.all(torch.abs(out0-out4)<1e-5))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"usmfFh4Ammjz"},"source":["print(out4.shape,out0.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iAdN1HM56sHV"},"source":["print('Equal4: ',torch.all(torch.abs(out3-out_-bias_)<1e-5))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f6HhtHl562kA"},"source":["print(out_.shape)"],"execution_count":null,"outputs":[]}]}